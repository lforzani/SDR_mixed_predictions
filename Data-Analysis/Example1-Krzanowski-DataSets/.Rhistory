###################################
####set to 0
costos_PCA_MIX=matrix(0,nrow=n,ncol=p_dim)
costos_PCA=matrix(0,nrow=n,ncol=p_dim)
#creat the 5 folders
set.seed(1000)
#cat("== starting ps procedure for PFCMix (this can take several minutes)===")
for (ps in 1:p_dim){
#cat("finished p0 = ", ps)
print(ps)
######### elegimos el corte optimo #######
for (i in 1:n) {
# cat(", finished i = ", i)
#Randomly shuffle the data
######A) datos repartii=1dos
#Segement your data by fold using the which() function
M_l_testing <- Base_mixed[i, ]
M_l_training <- Base_mixed[-i, ]
############################
##############Working on training
############################
### choosing the ps indexes that gives the combinations closes to PCA and PCA mix
#######using all the variables
indices=PCA_ambos(M_l_training,N0,.1,p_dim,ps)
####### Find the linear combinations, for that we need to acoomodate the variables
#####acomodo los indices para PCA comun PCAmix
acomodate_data=accomodate_variables_for_PCA_PCAmix(indices[2,],c,b,o,M_l_training)
###PCA comun
Total_final_PCA=acomodate_data$XXsubset
###PCA mix
acomodate_data=accomodate_variables_for_PCA_PCAmix(indices[1,],c,b,o,M_l_training)
X_final=acomodate_data$Xsubset
Cual_final=acomodate_data$Cualsubset
##############
##############en M$score y M_PCA$score estan las combinaciones lineales
##mix
M=PCAmix(X.quanti = X_final, X.quali =Cual_final, ndim = 2, rename.level = TRUE,
weight.col.quanti = NULL, weight.col.quali = NULL, graph = FALSE)
##pc comun
M_PCA=prcomp(Total_final_PCA,rank=1)
##########C) aplico glmfit y glm a los scorse (combinaciones lineales de PCA) en el training
#####miro los scores de cada una en el training
M_scores=M$scores[,1]
M_PCA_scores=predict(M_PCA,Total_final_PCA)[,1]
#####PCA_mix
datos_PCA_mix=data.frame(XX=M_scores,Y=M_l_training[,1])
glmfit_PCA_mix <- glm(Y~XX, data=datos_PCA_mix, family = 'binomial'(link = "logit"))
cutoff_optimo_pca_mix = cutoff.optimo.minMSE(glmfit_PCA_mix,M_l_training[,1],M_scores,trh)
#####PCA_comun
datos_PCA=data.frame(XX=M_PCA_scores,Y=M_l_training[,1])
glmfit_PCA <- glm(Y~XX, data=datos_PCA, family = 'binomial'(link = "logit"))
cutoff_optimo_pca = cutoff.optimo.minMSE(glmfit_PCA,M_l_training[,1],M_PCA_scores,trh)
##############
##############
##############Working on the test
##############
###############
#######A) see the liPampeanar combination on the test
#####acomodate the index for PCA and PCAmix
acomodate_data=accomodate_variables_for_PCA_PCAmix(indices[2,],c,b,o,M_l_testing)
###PCA comun
Total_final_PCA_test=acomodate_data$XXsubset
###PCA mix
acomodate_data=accomodate_variables_for_PCA_PCAmix(indices[1,],c,b,o,M_l_testing)
X_final_test=acomodate_data$Xsubset
Cual_final_test=acomodate_data$Cualsubset
aux = names(Cual_final_test)
#if the dimension of the conitnuos is 1 i need a matrix instead of a vector
if(!is.null(X_final_test) & is.null(dim(X_final_test)[1])){X_final_test=as.matrix(X_final_test)}
if(!is.null(Cual_final_test)){Cual_final_test=matrix(Cual_final_test, nrow = 1)
colnames(Cual_final_test) <- aux}
#############################
#predict on MIX (new scores)
Mnew=predict(M,X.quanti=X_final_test,X.quali=Cual_final_test)
aux=setdiff(names(Total_final_PCA),names(Total_final_PCA_test))
if (length(aux)!=0){
Total_final_PCA_test[aux]=0}
#predict of PCA
Mnew_PCA=predict(M_PCA,Total_final_PCA_test)
##########################
##########B) predcition on the new score
# PCAmix
Mnew_datos = data.frame(XX=Mnew[,1],Y=M_l_testing[,1])
Mnew_aux_PCA_mix_glm = predict(glmfit_PCA_mix, newdata =  Mnew_datos, type = "response")
yhat_PCA_mix = 1*(Mnew_aux_PCA_mix_glm > cutoff_optimo_pca_mix)
costos_PCA_MIX[i,ps] = 1-mean(yhat_PCA_mix == M_l_testing[,1])
# PCA
Mnew_datos = data.frame(XX=Mnew_PCA[,1],Y=M_l_testing[,1])
Mnew_aux_PCA_glm = predict(glmfit_PCA, newdata =  Mnew_datos, type = "response")
yhat_PCA = 1*(Mnew_aux_PCA_glm > cutoff_optimo_pca)
costos_PCA[i,ps] = 1-mean(yhat_PCA == M_l_testing[,1])
#########C) save the predictions
# resultados_PCA_MIX_glm = data.frame("fiteados"= Mnew_aux_PCA_mix_glm, "verdaderos"=M_l_testing[,1])
#
#
# resultados_PCA_glm = data.frame("fiteados"= Mnew_aux_PCA_glm, "verdaderos"=M_l_testing[,1])
#
#######D) miro para cada test i la funcion que estoy mirando que hace lo mejor posible
#phat_PCA_MIX[i] = resultados_PCA_MIX_glm$fiteados
#phat_PCA[i] = resultados_PCA_MIX_glm$fiteados
#Yverdaderas = Base_mixed[1,]
# guardar los modelos para usarlos ocon el cutoff optimo
# para clasificar
# aux_pca_mix = cutoff.optimo(Yverdaderas, phat_PCA_MIX)
# costos_PCA_MIX[i,ps]=aux_pca_mix[2]
# aux_pca = cutoff.optimo(Yverdaderas, phat_PCA)
# costos_PCA[i,ps]=aux_pca[2]
}
}
#cat("== starting ps procedure for PFCMix (this can take several minutes)===")
for (ps in 1:p_dim){
#cat("finished p0 = ", ps)
print(ps)
######### elegimos el corte optimo #######
for (i in 1:n) {
# cat(", finished i = ", i)
#Randomly shuffle the data
######A) datos repartii=1dos
#Segement your data by fold using the which() function
M_l_testing <- Base_mixed[i, ]
M_l_training <- Base_mixed[-i, ]
############################
##############Working on training
############################
### choosing the ps indexes that gives the combinations closes to PCA and PCA mix
#######using all the variables
indices=PCA_ambos(M_l_training,N0,.1,p_dim,ps)
####### Find the linear combinations, for that we need to acoomodate the variables
#####acomodo los indices para PCA comun PCAmix
acomodate_data=accomodate_variables_for_PCA_PCAmix(indices[2,],c,b,o,M_l_training)
###PCA comun
Total_final_PCA=acomodate_data$XXsubset
###PCA mix
acomodate_data=accomodate_variables_for_PCA_PCAmix(indices[1,],c,b,o,M_l_training)
X_final=acomodate_data$Xsubset
Cual_final=acomodate_data$Cualsubset
##############
##############en M$score y M_PCA$score estan las combinaciones lineales
##mix
M=PCAmix(X.quanti = X_final, X.quali =Cual_final, ndim = 2, rename.level = TRUE,
weight.col.quanti = NULL, weight.col.quali = NULL, graph = FALSE)
##pc comun
M_PCA=prcomp(Total_final_PCA,rank=1)
##########C) aplico glmfit y glm a los scorse (combinaciones lineales de PCA) en el training
#####miro los scores de cada una en el training
M_scores=M$scores[,1]
M_PCA_scores=predict(M_PCA,Total_final_PCA)[,1]
#####PCA_mix
datos_PCA_mix=data.frame(XX=M_scores,Y=M_l_training[,1])
glmfit_PCA_mix <- glm(Y~XX, data=datos_PCA_mix, family = 'binomial'(link = "logit"))
cutoff_optimo_pca_mix = cutoff.optimo.minMSE(glmfit_PCA_mix,M_l_training[,1],M_scores,trh)
#####PCA_comun
datos_PCA=data.frame(XX=M_PCA_scores,Y=M_l_training[,1])
glmfit_PCA <- glm(Y~XX, data=datos_PCA, family = 'binomial'(link = "logit"))
cutoff_optimo_pca = cutoff.optimo.minMSE(glmfit_PCA,M_l_training[,1],M_PCA_scores,trh)
##############
##############
##############Working on the test
##############
###############
#######A) see the liPampeanar combination on the test
#####acomodate the index for PCA and PCAmix
acomodate_data=accomodate_variables_for_PCA_PCAmix(indices[2,],c,b,o,M_l_testing)
###PCA comun
Total_final_PCA_test=acomodate_data$XXsubset
###PCA mix
acomodate_data=accomodate_variables_for_PCA_PCAmix(indices[1,],c,b,o,M_l_testing)
X_final_test=acomodate_data$Xsubset
Cual_final_test=acomodate_data$Cualsubset
aux = names(Cual_final_test)
#if the dimension of the conitnuos is 1 i need a matrix instead of a vector
if(!is.null(X_final_test) & is.null(dim(X_final_test)[1])){X_final_test=as.matrix(X_final_test)}
if(!is.null(Cual_final_test)){Cual_final_test=matrix(Cual_final_test, nrow = 1)
colnames(Cual_final_test) <- aux}
#############################
#predict on MIX (new scores)
Mnew=predict(M,X.quanti=X_final_test,X.quali=Cual_final_test)
aux=setdiff(names(Total_final_PCA),names(Total_final_PCA_test))
if (length(aux)!=0){
Total_final_PCA_test[aux]=0}
#predict of PCA
Mnew_PCA=predict(M_PCA,Total_final_PCA_test)
##########################
##########B) predcition on the new score
# PCAmix
Mnew_datos = data.frame(XX=Mnew[,1],Y=M_l_testing[,1])
Mnew_aux_PCA_mix_glm = predict(glmfit_PCA_mix, newdata =  Mnew_datos, type = "response")
yhat_PCA_mix = 1*(Mnew_aux_PCA_mix_glm > cutoff_optimo_pca_mix)
costos_PCA_MIX[i,ps] = 1-mean(yhat_PCA_mix == M_l_testing[,1])
# PCA
Mnew_datos = data.frame(XX=Mnew_PCA[,1],Y=M_l_testing[,1])
Mnew_aux_PCA_glm = predict(glmfit_PCA, newdata =  Mnew_datos, type = "response")
yhat_PCA = 1*(Mnew_aux_PCA_glm > cutoff_optimo_pca)
costos_PCA[i,ps] = 1-mean(yhat_PCA == M_l_testing[,1])
#########C) save the predictions
# resultados_PCA_MIX_glm = data.frame("fiteados"= Mnew_aux_PCA_mix_glm, "verdaderos"=M_l_testing[,1])
#
#
# resultados_PCA_glm = data.frame("fiteados"= Mnew_aux_PCA_glm, "verdaderos"=M_l_testing[,1])
#
#######D) miro para cada test i la funcion que estoy mirando que hace lo mejor posible
#phat_PCA_MIX[i] = resultados_PCA_MIX_glm$fiteados
#phat_PCA[i] = resultados_PCA_MIX_glm$fiteados
#Yverdaderas = Base_mixed[1,]
# guardar los modelos para usarlos ocon el cutoff optimo
# para clasificar
# aux_pca_mix = cutoff.optimo(Yverdaderas, phat_PCA_MIX)
# costos_PCA_MIX[i,ps]=aux_pca_mix[2]
# aux_pca = cutoff.optimo(Yverdaderas, phat_PCA)
# costos_PCA[i,ps]=aux_pca[2]
}
}
#looking for the ps in each cases that makes minimum cost
ps_optimo_PCA_glm=which.min(apply(costos_PCA,2,mean))
ps_optimo_PCA_mix_glm=which.min(apply(costos_PCA_MIX,2,mean))
M_l_testing <- Base_mixed
M_l_training <- Base_mixed
indice_final_PCA_glm = PCA_ambos(M_l_training,N0,.1,p_dim,ps_optimo_PCA_glm)[2,]
indice_final_PCA_MIX_glm = PCA_ambos(M_l_training,N0,.1,p_dim,ps_optimo_PCA_mix_glm)[1,]
indices=indice_final_PCA_glm
acomodate_data=accomodate_variables_for_PCA_PCAmix(indices,c,b,o,M_l_training)
Total_final_PCA_glm=acomodate_data$XXsubset
indices=indice_final_PCA_MIX_glm
acomodate_data=accomodate_variables_for_PCA_PCAmix(indices,c,b,o,M_l_training)
X_final=acomodate_data$Xsubset
Cual_final=acomodate_data$Cualsubset
##mix
M=PCAmix(X.quanti = X_final, X.quali =Cual_final, ndim = 2, rename.level = TRUE,
weight.col.quanti = NULL, weight.col.quali = NULL, graph = FALSE)
##pc comun
M_PCA=prcomp(Total_final_PCA,rank=1)
#####miro los scores de cada una en el training
M_scores=M$scores[,1]
M_PCA_scores=predict(M_PCA,Total_final_PCA)[,1]
#####PCA_mix
datos_PCA_mix=data.frame(XX=M_scores,Y=M_l_training[,1])
glmfit_PCA_mix <- glm(Y~XX, data=datos_PCA_mix, family = 'binomial'(link = "logit"))
cutoff_optimo_pca_mix = cutoff.optimo.minMSE(glmfit_PCA_mix,M_l_training[,1],M_scores,trh)
#####PCA_comun
datos_PCA=data.frame(XX=M_PCA_scores,Y=M_l_training[,1])
length(M_PCA_scores)
length(M_l_training)
length(M_l_training[,1])
length(b)
length(Base_mixed)
dim(Base_mixed)
length( M_scores=M$scores[,1])
length( M_scores)
M_PCA_scores=predict(M_PCA,Total_final_PCA)[,1]
length((M_PCA_scores))
length(M_PCA,Total_final_PCA)
M_PCA,Total_final_PCA
length(Total_final_PCA)
dim(Total_final_PCA)
dim(M_PCA)
length(M_PCA)
M_PCA
Total_final_PCA=acomodate_data$XXsubset
dim(Total_final_PCA)
dim(Cual_final)
##pc comun
M_PCA=prcomp(Total_final_PCA,rank=1)
#####miro los scores de cada una en el training
M_scores=M$scores[,1]
predict(M_PCA,Total_final_PCA)
M_PCA_scores=predict(M_PCA,Total_final_PCA)[,1]
M_PCA_scores
#####PCA_mix
datos_PCA_mix=data.frame(XX=M_scores,Y=M_l_training[,1])
glmfit_PCA_mix <- glm(Y~XX, data=datos_PCA_mix, family = 'binomial'(link = "logit"))
cutoff_optimo_pca_mix = cutoff.optimo.minMSE(glmfit_PCA_mix,M_l_training[,1],M_scores,trh)
#####PCA_comun
datos_PCA=data.frame(XX=M_PCA_scores,Y=M_l_training[,1])
glmfit_PCA <- glm(Y~XX, data=datos_PCA, family = 'binomial'(link = "logit"))
cutoff_optimo_pca = cutoff.optimo.minMSE(glmfit_PCA,M_l_training[,1],M_PCA_scores,trh)
acomodate_data=accomodate_variables_for_PCA_PCAmix(indices[2,],c,b,o,M_l_testing)
###PCA comun
Total_final_PCA_test=acomodate_data$XXsubset
###PCA mix
acomodate_data=accomodate_variables_for_PCA_PCAmix(indices[1,],c,b,o,M_l_testing)
#looking for the ps in each cases that makes minimum cost
ps_optimo_PCA_glm=which.min(apply(costos_PCA,2,mean))
ps_optimo_PCA_mix_glm=which.min(apply(costos_PCA_MIX,2,mean))
M_l_testing <- Base_mixed
M_l_training <- Base_mixed
indice_final_PCA_glm = PCA_ambos(M_l_training,N0,.1,p_dim,ps_optimo_PCA_glm)[2,]
indice_final_PCA_MIX_glm = PCA_ambos(M_l_training,N0,.1,p_dim,ps_optimo_PCA_mix_glm)[1,]
indices=indice_final_PCA_glm
acomodate_data=accomodate_variables_for_PCA_PCAmix(indices,c,b,o,M_l_training)
Total_final_PCA_glm=acomodate_data$XXsubset
indices=indice_final_PCA_MIX_glm
acomodate_data=accomodate_variables_for_PCA_PCAmix(indices,c,b,o,M_l_training)
X_final=acomodate_data$Xsubset
Cual_final=acomodate_data$Cualsubset
#if the dimension of the conitnuos is 1 i need a matrix instead of a vector
if(!is.null(X_final) & is.null(dim(X_final)[1])){X_final=as.matrix(X_final)}
X_final_PCA_mix_glm=X_final
Cual_final_PCA_mix_glm=Cual_final
M_glm=PCAmix(X.quanti = X_final_PCA_mix_glm, X.quali =Cual_final_PCA_mix_glm, ndim = 2, rename.level = TRUE,
weight.col.quanti = NULL, weight.col.quali = NULL, graph = FALSE)
M_PCA_glm=prcomp(Total_final_PCA_glm,rank=1)
M_glm_scores=M_glm$scores[,1]
M_PCA_scores_glm=predict(M_PCA_glm,Total_final_PCA_glm)[,1]
#####PCA_mix glm
datos_PCA_mix_glm=data.frame(XX=M_glm_scores,Y=M_l_training[,1] )
glmfit_PCA_mix_glm <- glm(Y~XX, data=datos_PCA_mix_glm, family = 'binomial'(link = "logit"))
hatprobaPCAmix =predict(glmfit_PCA_mix_glm)
datarocmix= data.frame(XXX=hatprobaPCAmix,Y=M_l_training[,1] )
AUC_PCA_mix = auc(roc_PCA_mix)
#####PCA_mix glm
datos_PCA_glm=data.frame(XX=M_PCA_scores_glm,Y=M_l_training[,1] )
#AUC
roc_PCA_mix <- roc(data=datarocmix,Y, XXX)
glmfit_PCA_glm <- glm(Y~XX, data=datos_PCA_glm, family = 'binomial'(link = "logit"))
hatprobaPCA =predict(glmfit_PCA_glm)
#AUC
dataroc= data.frame(XXX=hatprobaPCA,Y=M_l_training[,1] )
roc_PCA <- roc(data=dataroc, Y, XXX)
AUC_PCA= auc(roc_PCA)
return(list(AUC_PCA_mix=AUC_PCA_mix,AUC_PCA=AUC_PCA))
AUC_PCA_mix = auc(roc_PCA_mix)
AUC_PCA
AUC_PCA_mix
#path rodrigo
source("C:/Users/admin/Dropbox/diego-pame-rodrigo/Mixto/Codigo_Mixtos/independiente2019/funciones PCA-PCAmix/fuente.discreta.AUC.R")
setone = read.csv("C:/Users/admin/Dropbox/diego-pame-rodrigo/Mixto/Codigo_Mixtos/independiente2019/Datos/data-Krzanowski/setone.csv", header=FALSE, sep=";")
settwo = read.csv("C:/Users/admin/Dropbox/diego-pame-rodrigo/Mixto/Codigo_Mixtos/independiente2019/Datos/data-Krzanowski/settwo.csv", header=FALSE, sep=";")
setthree = read.csv("C:/Users/admin/Dropbox/diego-pame-rodrigo/Mixto/Codigo_Mixtos/independiente2019/Datos/data-Krzanowski/setthree.csv", header=FALSE, sep=";")
setfour = read.csv("C:/Users/admin/Dropbox/diego-pame-rodrigo/Mixto/Codigo_Mixtos/independiente2019/Datos/data-Krzanowski/setfour.csv", header=FALSE, sep=";")
# # set four
setfour = cbind(setfour[,1:4], log(setfour[,5:6]), setfour[,7:12])
datos= setfour[,c(12,1:11)]
o=NULL
c=c(2:7)
b=c(8:10)
attach(datos)
n = dim(datos)[1]
Base_mixed=datos
# el orden en Base_mixed debe ser: Y, Continuas, Binarias
# o, c, b son los indices donde estan las variables Ordinales (aca es nulo),
# Continuas y Binarias
library(readr)
library(fastDummies)
library(MLmetrics)
library(pROC)
trh = seq(0.2,0.8,0.05)
#path rodrigo
source("C:/Users/admin/Dropbox/diego-pame-rodrigo/Mixto/Codigo_Mixtos/independiente2019/funciones PCA-PCAmix/cutoff.optimo.minMSE.R")
source("C:/Users/admin/Dropbox/diego-pame-rodrigo/Mixto/Codigo_Mixtos/independiente2019/funciones PCA-PCAmix/PCA_ambos.R")
source("C:/Users/admin/Dropbox/diego-pame-rodrigo/Mixto/Codigo_Mixtos/independiente2019/funciones PCA-PCAmix/accomodate_variables_for_PCA_PCAmix.R")
#opcion 2
N0=1000
n = dim(Base_mixed)[1]
##dimmension of the predictores
p_dim = length(o)+length(b)+length(c)
####################################
####################################
####################################
###
###################################
######################################
###################################
####set to 0
costos_PCA_MIX=matrix(0,nrow=n,ncol=p_dim)
costos_PCA=matrix(0,nrow=n,ncol=p_dim)
#creat the 5 folders
set.seed(1000)
#cat("== starting ps procedure for PFCMix (this can take several minutes)===")
for (ps in 1:p_dim){
#cat("finished p0 = ", ps)
print(ps)
######### elegimos el corte optimo #######
for (i in 1:n) {
# cat(", finished i = ", i)
#Randomly shuffle the data
######A) datos repartii=1dos
#Segement your data by fold using the which() function
M_l_testing <- Base_mixed[i, ]
M_l_training <- Base_mixed[-i, ]
############################
##############Working on training
############################
### choosing the ps indexes that gives the combinations closes to PCA and PCA mix
#######using all the variables
indices=PCA_ambos(M_l_training,N0,.1,p_dim,ps)
####### Find the linear combinations, for that we need to acoomodate the variables
#####acomodo los indices para PCA comun PCAmix
acomodate_data=accomodate_variables_for_PCA_PCAmix(indices[2,],c,b,o,M_l_training)
###PCA comun
Total_final_PCA=acomodate_data$XXsubset
###PCA mix
acomodate_data=accomodate_variables_for_PCA_PCAmix(indices[1,],c,b,o,M_l_training)
X_final=acomodate_data$Xsubset
Cual_final=acomodate_data$Cualsubset
##############
##############en M$score y M_PCA$score estan las combinaciones lineales
##mix
M=PCAmix(X.quanti = X_final, X.quali =Cual_final, ndim = 2, rename.level = TRUE,
weight.col.quanti = NULL, weight.col.quali = NULL, graph = FALSE)
##pc comun
M_PCA=prcomp(Total_final_PCA,rank=1)
##########C) aplico glmfit y glm a los scorse (combinaciones lineales de PCA) en el training
#####miro los scores de cada una en el training
M_scores=M$scores[,1]
M_PCA_scores=predict(M_PCA,Total_final_PCA)[,1]
#####PCA_mix
datos_PCA_mix=data.frame(XX=M_scores,Y=M_l_training[,1])
glmfit_PCA_mix <- glm(Y~XX, data=datos_PCA_mix, family = 'binomial'(link = "logit"))
cutoff_optimo_pca_mix = cutoff.optimo.minMSE(glmfit_PCA_mix,M_l_training[,1],M_scores,trh)
#####PCA_comun
datos_PCA=data.frame(XX=M_PCA_scores,Y=M_l_training[,1])
glmfit_PCA <- glm(Y~XX, data=datos_PCA, family = 'binomial'(link = "logit"))
cutoff_optimo_pca = cutoff.optimo.minMSE(glmfit_PCA,M_l_training[,1],M_PCA_scores,trh)
##############
##############
##############Working on the test
##############
###############
#######A) see the liPampeanar combination on the test
#####acomodate the index for PCA and PCAmix
acomodate_data=accomodate_variables_for_PCA_PCAmix(indices[2,],c,b,o,M_l_testing)
###PCA comun
Total_final_PCA_test=acomodate_data$XXsubset
###PCA mix
acomodate_data=accomodate_variables_for_PCA_PCAmix(indices[1,],c,b,o,M_l_testing)
X_final_test=acomodate_data$Xsubset
Cual_final_test=acomodate_data$Cualsubset
aux = names(Cual_final_test)
#if the dimension of the conitnuos is 1 i need a matrix instead of a vector
if(!is.null(X_final_test) & is.null(dim(X_final_test)[1])){X_final_test=as.matrix(X_final_test)}
if(!is.null(Cual_final_test)){Cual_final_test=matrix(Cual_final_test, nrow = 1)
colnames(Cual_final_test) <- aux}
#############################
#predict on MIX (new scores)
Mnew=predict(M,X.quanti=X_final_test,X.quali=Cual_final_test)
aux=setdiff(names(Total_final_PCA),names(Total_final_PCA_test))
if (length(aux)!=0){
Total_final_PCA_test[aux]=0}
#predict of PCA
Mnew_PCA=predict(M_PCA,Total_final_PCA_test)
##########################
##########B) predcition on the new score
# PCAmix
Mnew_datos = data.frame(XX=Mnew[,1],Y=M_l_testing[,1])
Mnew_aux_PCA_mix_glm = predict(glmfit_PCA_mix, newdata =  Mnew_datos, type = "response")
yhat_PCA_mix = 1*(Mnew_aux_PCA_mix_glm > cutoff_optimo_pca_mix)
costos_PCA_MIX[i,ps] = 1-mean(yhat_PCA_mix == M_l_testing[,1])
# PCA
Mnew_datos = data.frame(XX=Mnew_PCA[,1],Y=M_l_testing[,1])
Mnew_aux_PCA_glm = predict(glmfit_PCA, newdata =  Mnew_datos, type = "response")
yhat_PCA = 1*(Mnew_aux_PCA_glm > cutoff_optimo_pca)
costos_PCA[i,ps] = 1-mean(yhat_PCA == M_l_testing[,1])
#########C) save the predictions
# resultados_PCA_MIX_glm = data.frame("fiteados"= Mnew_aux_PCA_mix_glm, "verdaderos"=M_l_testing[,1])
#
#
# resultados_PCA_glm = data.frame("fiteados"= Mnew_aux_PCA_glm, "verdaderos"=M_l_testing[,1])
#
#######D) miro para cada test i la funcion que estoy mirando que hace lo mejor posible
#phat_PCA_MIX[i] = resultados_PCA_MIX_glm$fiteados
#phat_PCA[i] = resultados_PCA_MIX_glm$fiteados
#Yverdaderas = Base_mixed[1,]
# guardar los modelos para usarlos ocon el cutoff optimo
# para clasificar
# aux_pca_mix = cutoff.optimo(Yverdaderas, phat_PCA_MIX)
# costos_PCA_MIX[i,ps]=aux_pca_mix[2]
# aux_pca = cutoff.optimo(Yverdaderas, phat_PCA)
# costos_PCA[i,ps]=aux_pca[2]
}
}
#looking for the ps in each cases that makes minimum cost
ps_optimo_PCA_glm=which.min(apply(costos_PCA,2,mean))
ps_optimo_PCA_mix_glm=which.min(apply(costos_PCA_MIX,2,mean))
M_l_testing <- Base_mixed
M_l_training <- Base_mixed
indice_final_PCA_glm = PCA_ambos(M_l_training,N0,.1,p_dim,ps_optimo_PCA_glm)[2,]
indice_final_PCA_MIX_glm = PCA_ambos(M_l_training,N0,.1,p_dim,ps_optimo_PCA_mix_glm)[1,]
indices=indice_final_PCA_glm
acomodate_data=accomodate_variables_for_PCA_PCAmix(indices,c,b,o,M_l_training)
Total_final_PCA_glm=acomodate_data$XXsubset
indices=indice_final_PCA_MIX_glm
acomodate_data=accomodate_variables_for_PCA_PCAmix(indices,c,b,o,M_l_training)
X_final=acomodate_data$Xsubset
Cual_final=acomodate_data$Cualsubset
#if the dimension of the conitnuos is 1 i need a matrix instead of a vector
if(!is.null(X_final) & is.null(dim(X_final)[1])){X_final=as.matrix(X_final)}
X_final_PCA_mix_glm=X_final
Cual_final_PCA_mix_glm=Cual_final
M_glm=PCAmix(X.quanti = X_final_PCA_mix_glm, X.quali =Cual_final_PCA_mix_glm, ndim = 2, rename.level = TRUE,
weight.col.quanti = NULL, weight.col.quali = NULL, graph = FALSE)
M_PCA_glm=prcomp(Total_final_PCA_glm,rank=1)
M_glm_scores=M_glm$scores[,1]
M_PCA_scores_glm=predict(M_PCA_glm,Total_final_PCA_glm)[,1]
#####PCA_mix glm
datos_PCA_mix_glm=data.frame(XX=M_glm_scores,Y=M_l_training[,1] )
glmfit_PCA_mix_glm <- glm(Y~XX, data=datos_PCA_mix_glm, family = 'binomial'(link = "logit"))
hatprobaPCAmix =predict(glmfit_PCA_mix_glm)
datarocmix= data.frame(XXX=hatprobaPCAmix,Y=M_l_training[,1] )
#AUC
roc_PCA_mix <- roc(data=datarocmix,Y, XXX)
AUC_PCA_mix = auc(roc_PCA_mix)
#####PCA_mix glm
datos_PCA_glm=data.frame(XX=M_PCA_scores_glm,Y=M_l_training[,1] )
glmfit_PCA_glm <- glm(Y~XX, data=datos_PCA_glm, family = 'binomial'(link = "logit"))
hatprobaPCA =predict(glmfit_PCA_glm)
#AUC
dataroc= data.frame(XXX=hatprobaPCA,Y=M_l_training[,1] )
roc_PCA <- roc(data=dataroc, Y, XXX)
AUC_PCA= auc(roc_PCA)
return(list(AUC_PCA_mix=AUC_PCA_mix,AUC_PCA=AUC_PCA))
AUC_PCA
AUC_PCA_mix
